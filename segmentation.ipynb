{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google colab\n",
    "# !python -m pip install pyyaml==5.1\n",
    "# import sys, os, distutils.core\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, cv2, tqdm\n",
    "\n",
    "# import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data.datasets import register_coco_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the coco dataset\n",
    "path = \"dataset\"\n",
    "# path = \"/content/drive/MyDrive/Colab Notebooks/MLPROJECT/dataset/\" # for google colab\n",
    "register_coco_instances(\n",
    "    \"bathroom-dataset\",\n",
    "    {},\n",
    "    f\"{path}/annotations/instances_default.json\",\n",
    "    f\"{path}/images/\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata and dataset\n",
    "bathroom_metadata = MetadataCatalog.get(\"bathroom-dataset\")\n",
    "dataset_dicts = DatasetCatalog.get(\"bathroom-dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up model configuration\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "# cfg.MODEL.DEVICE = \"cuda\" # for google colab\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "cfg.DATASETS.TRAIN = (\"bathroom-dataset\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    ")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 2000\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL ON THE DATASET (UNCOMMENT TO TRAIN)\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "# trainer = DefaultTrainer(cfg)\n",
    "# trainer.resume_or_load(resume=False)\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model from file and create predictor\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the video using the predictor\n",
    "v = VideoVisualizer(\n",
    "    MetadataCatalog.get(\"bathroom-dataset\"), instance_mode=ColorMode.IMAGE\n",
    ")\n",
    "\n",
    "\n",
    "def runvideo(video, maxFrames):\n",
    "    readframes = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        outputs = predictor(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        visualization = v.draw_instance_predictions(\n",
    "            frame, outputs[\"instances\"].to(\"cpu\")\n",
    "        )\n",
    "\n",
    "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        yield visualization\n",
    "\n",
    "        readframes += 1\n",
    "        if readframes > maxFrames:\n",
    "            break\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "video_writer = cv2.VideoWriter(\n",
    "    \"segmented-video.mp4\",\n",
    "    fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps=float(frames_per_second),\n",
    "    frameSize=(frame_width, frame_height),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "for visualization in tqdm.tqdm(runvideo(video, num_frames), total=num_frames):\n",
    "    video_writer.write(visualization)\n",
    "\n",
    "video.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
